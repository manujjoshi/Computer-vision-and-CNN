{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8726fd2",
   "metadata": {},
   "source": [
    "# `Object detection using Mask-RCNN`\n",
    "## `Mask-RCNN on custom dataset` (tough one)\n",
    "### It also predict the region of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559b1bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973228ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.engine' has no attribute 'Layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-79beac7bb0d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay_images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay_instances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mrcnn\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mProposalLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     \"\"\"Receives anchor scores and selects a subset to pass as proposals\n\u001b[0;32m    257\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msecond\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mFiltering\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdone\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0manchor\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.engine' has no attribute 'Layer'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "\n",
    "# root directory of the project\n",
    "ROOT_DIR = r'C:\\Users\\manuj\\DL_Concepts\\CNN\\Mask_RCNN'\n",
    "\n",
    "DEFAULT_LOGS_DIR =os.path.join(ROOT_DIR,'logs')\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR,'\\model')\n",
    "\n",
    "WEIGHTS_PATH = r'C:\\Users\\manuj\\DL_Concepts\\CNN\\Mask_RCNN\\model\\mask_rcnn_coco.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c335ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    NAME = 'object'\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 3 # background + phone + laptop + tablet\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CustomConfig()\n",
    "CUSTOM_DIR = os.path.join(ROOT_DIR,'/dataset/')\n",
    "\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "    def load_custom(self,dataset_dir,subset):\n",
    "        self.add_class('object',1,'laptop')\n",
    "        self.add_class('object',2,'tablet')\n",
    "        self.add_class('object',1,'mobile')\n",
    "        \n",
    "        assert subset in ['train','val']\n",
    "        dataset_dir = os.path.join(dataset_dir,subset)\n",
    "        annotation1 = json.load(open(r'C:\\Users\\manuj\\DL_Concepts\\CNN\\Mask_RCNN\\project.json'))\n",
    "        \n",
    "        annotations = list(annotation1.values())\n",
    "        \n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "        \n",
    "        ## add images\n",
    "        \n",
    "        for a in annotations:\n",
    "            \n",
    "            polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "            objects = [s['region_attributes']['names'] for s in a['regions']]\n",
    "            print('objects:',objects)\n",
    "            name_dict = {'laptop':1,'tablet':2,'mobile':3}\n",
    "            num_ids = [name_dict[a] for a in objects]\n",
    "            \n",
    "            print('numids',num_ids)\n",
    "            image_path = os.path.join(dataset_dir,a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            \n",
    "            # usng opencv, please convert from BGR to RGB\n",
    "            height,width = image.shape[:2]\n",
    "            \n",
    "            self.add_image(\n",
    "            'object',\n",
    "            image_id = a['filename'],\n",
    "            path = image_path,\n",
    "            width = width , height = height,\n",
    "            polygons = polygons,\n",
    "            num_ids = num_ids\n",
    "            )\n",
    "            \n",
    "    def load_mask(self,image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info['source'] != 'object':\n",
    "            return super(self.__class__.self).load_mask(image_id)\n",
    "        \n",
    "        info = self.image_info[image_id]\n",
    "        if info['source'] != 'object':\n",
    "            return super(self.__class__.self).load_mask(image_id)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info['height'],info['width'],len(info['polygons'])],\n",
    "                       dtype=np.uint8)\n",
    "        \n",
    "        for i,p in enumerate(info['polygons']):\n",
    "            rr,cc = skimage.draw.polygon(p['all_points_y'],p['all_points_x'])\n",
    "            \n",
    "            mask[rr,cc,i] = 1\n",
    "            \n",
    "            num_ids = np.array(num_ids,dtype=np.int32)\n",
    "            return mask,num_ids\n",
    "        \n",
    "    def image_reference(self,image_id):\n",
    "        # return the path of hte image\n",
    "        info = self.image_info[image_id]\n",
    "        if info['source'] == 'object':\n",
    "            return info['path']\n",
    "        else:\n",
    "            super(self.__class__.self).image_reference(image_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e81fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model in training or inference modes calues: 'inference','training'\n",
    "\n",
    "TEST_MODE = 'inference'\n",
    "ROOT_DIR = r'C:\\Users\\manuj\\DL_Concepts\\CNN\\Mask_RCNN'\n",
    "\n",
    "def get_ax(rows=1,cols=1,size=16):\n",
    "    _,ax = plt.subplots(rows,cols,figsize=(size*cols,size*rows))\n",
    "    return ax\n",
    "\n",
    "# load validation dataset\n",
    "# must call before using the dataset\n",
    "\n",
    "CUSTOM_DIR = r'C:\\Users\\manuj\\DL_Concepts\\CNN\\Mask_RCNN\\dataset'\n",
    "dataset = CustomDataset()\n",
    "dataset.load_custom(CUSTOM_DIR,'val')\n",
    "dataset.prepare\n",
    "print('Images: {}\\n Classes: {}'.format(len(dataset.image_ids),dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb15944",
   "metadata": {},
   "source": [
    "## `END -----------------------------------------------`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
