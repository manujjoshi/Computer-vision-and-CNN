{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7006e295",
   "metadata": {},
   "source": [
    "# `Image Augmentation and transfer learning with ASL Dataset`\n",
    "## `Alexnet model`:\n",
    "![](https://www.researchgate.net/profile/Alexander-Khvostikov/publication/322592079/figure/fig3/AS:584350454263818@1516331413967/AlexNet-architecture-Includes-5-convolutional-layers-and-3-fullyconnected-layers.png)\n",
    "\n",
    "## `vgg16 model`: (widely used)\n",
    "![](https://www.researchgate.net/profile/Bibo-Shi/publication/323440752/figure/fig1/AS:739814685032448@1553396974148/The-architecture-of-VGG-16-model-To-represent-different-depth-levels-convolutional.jpg)\n",
    "\n",
    "## `vgg19 model`:(to dig more than vgg16, extended model of vgg 16)\n",
    "![](https://www.researchgate.net/profile/Clifford-Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214fe094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1051f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r'E:\\ASL_dataset'  # r => read mode\n",
    "train_path = r'E:\\ASL_dataset\\asl-alphabet-train'\n",
    "test_path = r'E:\\ASL_dataset\\asl-alphabet-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aeab358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : 29\n",
      "['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "dirls = os.listdir(train_path)\n",
    "print('classes :',dirls.__len__())\n",
    "print(dirls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a08c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : 29\n",
      "['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "dirls = os.listdir(test_path)\n",
    "print('classes :',dirls.__len__())\n",
    "print(dirls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafb8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_path(path):\n",
    "    pathnames = []\n",
    "    dir_list = os.listdir(path)\n",
    "    uniq_class = sorted(dir_list)\n",
    "    for i in range(len(uniq_class)):\n",
    "        new_path = path + '\\\\' + uniq_class[i]\n",
    "        pathnames.append(new_path)\n",
    "    return (pathnames,uniq_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57571872",
   "metadata": {},
   "outputs": [],
   "source": [
    "path,classes = loading_path(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling_images(uniq_path, uniq_labels):\n",
    "    img_path = []\n",
    "    label = []\n",
    "    for path,Label in zip(uniq_path,uniq_labels):\n",
    "        dir_list = os.listdir(path)\n",
    "        for i in dir_list:\n",
    "            img_dir_list = path + '\\\\' + i\n",
    "            img_path.append(img_dir_list)\n",
    "            label.append(Label)\n",
    "    return (img_path,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path,label = labelling_images(path,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8135482",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dca929",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path[0])\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201c01d",
   "metadata": {},
   "source": [
    "### till here steps are same of reading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb392c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(img_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e878f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataset,columns=['Image_path','Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f04035",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    vals = np.random.randint(1,len(data))\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(data.Image_path[vals]),cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb234c7f",
   "metadata": {},
   "source": [
    "### we will split our data and then apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8124b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(data, train_size=0.8, random_state=0)\n",
    "train_new,valid = train_test_split(train, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_new.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a602af5",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=10,width_shift_range=.10,height_shift_range=.10,\n",
    "                                   shear_range=.10,zoom_range=0.10,horizontal_flip=True,vertical_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a55b8",
   "metadata": {},
   "source": [
    "### I will rescale train data later after visualization\n",
    "### apply our preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412371e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_dataframe(dataframe=train_new,x_col='Image_path',y_col='Labels',batch_size=16,target_size=(155,155),class_mode='categorical',shuffle=True)\n",
    "\n",
    "valid_gen = train_datagen.flow_from_dataframe(dataframe=valid,x_col='Image_path',y_col='Labels',batch_size=16,target_size=(155,155),class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = test_datagen.flow_from_dataframe(dataframe=test,x_col='Image_path',y_col='Labels',batch_size=16,target_size=(155,155),class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa3d86",
   "metadata": {},
   "source": [
    "### we have data in dataframe, so flow from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen[0][0].shape  # 16 is batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(12):\n",
    "    val = train_gen[0][0][i]\n",
    "    vals = val.astype('uint8')\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.imshow(vals)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3199166",
   "metadata": {},
   "source": [
    "### Now do rescaling of train data as we have visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=10,width_shift_range=.10,height_shift_range=.10,\n",
    "                                   shear_range=.10,zoom_range=0.10,horizontal_flip=True,vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_dataframe(dataframe=train_new,x_col='Image_path',y_col='Labels',batch_size=16,target_size=(155,155),class_mode='categorical',shuffle=True)\n",
    "\n",
    "valid_gen = train_datagen.flow_from_dataframe(dataframe=valid,x_col='Image_path',y_col='Labels',batch_size=16,target_size=(155,155),class_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a878a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(12):\n",
    "    val = train_gen[0][0][i]\n",
    "    vals = val.astype('uint8')\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.imshow(vals)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab199fd",
   "metadata": {},
   "source": [
    "### see it's all black after scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1e87a",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70535928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,MaxPool2D,Dense,Dropout,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet',input_shape=(155,155,3),include_top=False)\n",
    "# we want to add some other layers so False\n",
    "\n",
    "network = Sequential()\n",
    "network.add(base_model)\n",
    "network.add(GlobalAveragePooling2D())\n",
    "network.add(Dense(128,activation='relu'))\n",
    "network.add(Dropout(0.1))\n",
    "network.add(Dense(29,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "network.fit(train_gen,epochs=10,validation_data=valid_gen,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7d2c7",
   "metadata": {},
   "source": [
    "# `END ------------------------------`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
